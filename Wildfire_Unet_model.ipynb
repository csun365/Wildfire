{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom mpl_toolkits import mplot3d\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks, Sequential, Input, Model\nfrom tensorflow.keras.layers import Activation, Dropout, Dense, Add, BatchNormalization, Conv2D, SeparableConv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, Flatten, concatenate\nfrom sklearn.cluster import KMeans\n\nimport math\nimport scipy\nimport pickle\nimport gc \n\nfrom IPython.display import display","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nBand 0 - Coastal aerosol\n\nBand 1 - Blue\n\nBand 2 - Green\n\nBand 3 - Red\n\nBand 4 - Near Infrared (NIR)\n\nBand 5 - SWIR 1\n\nBand 6 - SWIR 2\n\nBand 7 - Cirrus\n\nBand 8 - Thermal Infrared (TIRS) 1\n\nBand 9 - Thermal Infrared (TIRS) 2\n\n(Panchromatic Band is Excluded)","metadata":{}},{"cell_type":"code","source":"# Train and Validation data from Ecuador/Galapagos\nfire_path = \"\"\nnonfire_path = \"\"\nmask_path = \"\"\n\nfires = pickle.load(open(fire_path, \"rb\"))\nnonfires = pickle.load(open(nonfire_path, \"rb\"))\nmasks = pickle.load(open(mask_path, \"rb\"))\nmasks = masks.astype(\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data from Guyana/Suriname\ntest_fire_path = \"\"\ntest_mask_path = \"\"\n\nfires_test = pickle.load(open(test_fire_path, \"rb\"))\nmasks_test = pickle.load(open(test_mask_path, \"rb\"))\nmasks_test = masks_test.astype(\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_idxs(data):\n    mins = np.min(data.reshape(data.shape[0], data.shape[1] * data.shape[2] * data.shape[3]), axis=0)\n    return np.array(np.nonzero(mins)).tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs_fire = return_idxs(fires)\nfires = fires[idxs_fire]\nmasks = masks[idxs_fire]\n\nidxs_nonfire = return_idxs(nonfires)\nnonfires = nonfires[indices_to_keep]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t, X_v, y_t, y_v = train_test_split(fires, masks, test_size=0.15, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Min-Max Normalization\nX_t_mins = np.min(np.min(np.min(X_t, axis=0), axis=0), axis=0) \nX_t_maxs = np.max(np.max(np.max(X_t, axis=0), axis=0), axis=0) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t = (X_t - X_t_mins) / (X_t_maxs - X_t_mins)\nX_v = (X_v - X_t_mins) / (X_t_maxs - X_t_mins)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing Test Data\nfires_test = (fires_test - X_t_mins) / (X_t_maxs - X_t_mins)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fires_m = fires.shape[0]\nnonfires_m = nonfires.shape[0]\ntot = fires_m + nonfires_m\nprint(\"Number of fires:\\t\" + str(fires_m))\nprint(\"Number of nonfires:\\t\" + str(nonfires_m))\nprint(\"Total:\\t\" + str(tot))\nprint(\"Percentage that are fire:\\t\" + str(fires_m/tot))\nprint(\"Percentage that are nonfire:\\t\" + str(nonfires_m/tot))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting a sense of the number of fires in each image\nnum_clusters = []\n\nfor i in range(500):\n    fires = np.array(list(np.where(masks[i] == 1))) # 2 x m array where m is the number of pixels that equal 1\n    cost = np.inf\n    clusters = 0\n    cost_threshold = np.sum(masks[i].reshape(masks[i].shape[0], masks[i].shape[1]**2), axis=1) / 3\n    while cost * 10 > cost_threshold:\n        clusters += 1\n        kmeans = KMeans(clusters)\n        kmeans.fit(fires.T)\n        cost = kmeans.inertia_\n    num_clusters.append(clusters)\nprint(num_clusters)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of pixels with active fires\n# Used for loss function weighting \nnum_fires = np.sum(np.sum(masks, axis=-1), axis=-1)\nplt.hist(num_fires,bins=50)\nplt.yscale('log')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize single 128 x 128 x 3 image for plotting\ndef plot_single(arr):\n    epsilon = 1e-4\n    reshaped_arr = arr.reshape(arr.shape[0] * arr.shape[1], arr.shape[2])\n    arr_min = np.min(reshaped_arr, axis=0)\n    arr_max = np.max(reshaped_arr, axis=0)\n    reshaped_arr_norm = (reshaped_arr - arr_min) / (arr_max - arr_min + epsilon) \n    img = reshaped_arr_norm.reshape(arr.shape[0], arr.shape[1], arr.shape[2])\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet_model():\n    inputs = Input(shape=(128, 128, 3))\n    conv1 = Conv2D(32, (3, 3), padding='same')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(32, (3, 3), padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation(\"relu\")(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(64, (3, 3), padding='same')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(64, (3, 3), padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation(\"relu\")(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), padding='same')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(128, (3, 3), padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation(\"relu\")(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(256, (3, 3), padding='same')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(256, (3, 3), padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation(\"relu\")(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    up5 = concatenate([Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n    conv5 = Conv2D(128, (3, 3), padding='same')(up5)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(128, (3, 3), padding='same')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation(\"relu\")(conv5)\n\n    up6 = concatenate([Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(conv5), conv2], axis=3)\n    conv6 = Conv2D(64, (3, 3), padding='same')(up6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(64, (3, 3), padding='same')(conv6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation(\"relu\")(conv6)\n\n    up7 = concatenate([Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(conv6), conv1], axis=3)\n    conv7 = Conv2D(32, (3, 3), padding='same')(up7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(16, (3, 3), padding='same')(conv7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation(\"relu\")(conv7)\n  \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_unet_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.keras.utils.plot_model(model, to_file='unet_model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weighting for class imbalance\nweight_pos = (masks.shape[0]*masks.shape[1]*masks.shape[2])/np.sum(num_fires) - 1 # weight_pos = 2095.5433356044036\n\ndef loss_fn(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    epsilon = 1e-4\n    error = - (weight_pos * y_true * tf.math.log(y_pred + epsilon) + (1 - y_true) * tf.math.log(1 - y_pred + epsilon))\n    # loss = weight1 * tf.cast(y_true == 1, dtype=tf.float32) * error + weight0 * tf.cast(y_true == 0, dtype=tf.float32) * error\n    loss = tf.math.reduce_mean(error, axis=-1)\n    \n    return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f2_score(y_true, y_pred):\n    y_pred = tf.cast(tf.math.greater_equal(y_pred, 0.5), tf.float32)\n    y_true = Flatten()(y_true)\n    y_pred = Flatten()(y_pred)\n    epsilon = 1e-4\n    tp = tf.math.logical_and((y_true == 1), (y_pred == 1))\n    tp = tf.cast(tp, tf.float32)\n    tp = tf.math.reduce_sum(tp, axis=1)\n    fp = tf.math.logical_and((y_true == 0), (y_pred == 1))\n    fp = tf.cast(fp, tf.float32)\n    fp = tf.math.reduce_sum(fp, axis=1)\n    fn = tf.math.logical_and((y_true == 1), (y_pred == 0))\n    fn = tf.cast(fn, tf.float32)\n    fn = tf.math.reduce_sum(fn, axis=1)\n    \n    return tp / (tp + 0.2 * fp + 0.8 * fn + epsilon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_pred = tf.cast(tf.math.greater_equal(y_pred, 0.5), tf.float32)\n    y_true = Flatten()(y_true)\n    y_pred = Flatten()(y_pred)\n    epsilon = 1e-4\n    tp = tf.math.logical_and((y_true == 1), (y_pred == 1))\n    tp = tf.cast(tp, tf.float32)\n    tp = tf.math.reduce_sum(tp, axis=1)\n    fp = tf.math.logical_and((y_true == 0), (y_pred == 1))\n    fp = tf.cast(fp, tf.float32)\n    fp = tf.math.reduce_sum(fp, axis=1)\n    fn = tf.math.logical_and((y_true == 1), (y_pred == 0))\n    fn = tf.cast(fn, tf.float32)\n    fn = tf.math.reduce_sum(fn, axis=1)\n    \n    return 2 * tp / (2 * tp + fp + fn + epsilon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    y_pred = tf.cast(tf.math.greater_equal(y_pred, 0.5), tf.float32)\n    y_true = Flatten()(y_true)\n    y_pred = Flatten()(y_pred)\n    epsilon = 1e-4\n    tp = tf.math.logical_and((y_true == 1), (y_pred == 1))\n    tp = tf.cast(tp, tf.float32)\n    tp = tf.math.reduce_sum(tp)\n    fp = tf.math.logical_and((y_true == 0), (y_pred == 1))\n    fp = tf.cast(fp, tf.float32)\n    fp = tf.math.reduce_sum(fp)\n    fn = tf.math.logical_and((y_true == 1), (y_pred == 0))\n    fn = tf.cast(fn, tf.float32)\n    fn = tf.math.reduce_sum(fn)\n    tn = tf.math.logical_and((y_true == 0), (y_pred == 0))\n    tn = tf.cast(tn, tf.float32)\n    tn = tf.math.reduce_sum(tn)\n    \n    return tp, fp, fn, tn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha0 = 5e-4\ndef lr_exp_decay(epoch, lr):\n    k = 0.1\n    return alpha0 * math.exp(-k * epoch)\n\nalpha_schedule = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay)\n\nadam = tf.keras.optimizers.Adam(learning_rate=alpha_schedule)\nmodel.compile(optimizer=\"adam\", loss=loss_fn, metrics=[f2_score, f1_score])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_t, y_t, validation_data=(X_v, y_v), batch_size=32, epochs=100, callbacks=[alpha_schedule])\n\nplt.plot(history.history[\"loss\"])\n# Rolling average\n# val_loss = history.history[\"val_loss\"][:9] + list(pd.Series(history.history[\"val_loss\"]).rolling(10).mean().dropna())\nplt.plot(history.history[\"val_loss\"])\n# plt.ylim(0,0.05)\nplt.show()\n\nplt.plot(history.history[\"f2_score\"])\n# Rolling average\n# val_f2 = history.history[\"val_f2_score\"][:9] + list(pd.Series(history.history[\"val_f2_score\"]).rolling(10).mean().dropna())\nplt.plot(history.history[\"val_f2_score\"])\nplt.ylim(0,1)\nplt.show()\n\nplt.plot(history.history[\"f1_score\"])\n# Rolling average\n# val_f1 = history.history[\"val_f1_score\"][:9] + list(pd.Series(history.history[\"val_f1_score\"]).rolling(10).mean().dropna())\nplt.plot(history.history[\"val_f1_score\"])\nplt.ylim(0,1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save_weights('unet_model_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance on validation set\ny_pred = model.predict(X_v, batch_size=32)\ny_pred = (y_pred >= 0.5).astype(\"int\")\nevaluate(y_v, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"/kaggle/input/ecuador-and-galapagos-wildfire-detection/my_model_weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance on test set (Guyana/Suriname images)\nevaluate(masks_test, model.predict(fires_test, batch_size=64))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffler = np.random.permutation(2000)\nnonfires_x_pred = nonfires[:,:,:,[2,5,6]]\nnonfires_x_pred = nonfires_x_pred[shuffler]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance on 2000 nonfire images (ideally should predict every pixel = 0)\nevaluate(np.zeros((2000,128,128)), model.predict(nonfires_x_pred, batch_size=32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}